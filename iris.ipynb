{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary libraries for data analysis and visualization.\n",
    "\n",
    "numpy A library used for working with arrays and performing numerical operations.\n",
    "\n",
    "matplotlib: A plotting library used for creating static, animated, and interactive visualizations.\n",
    "\n",
    "\n",
    "seaborn: A statistical data visualization library built on top of matplotlib, provides a high-level interface for drawing attractive and informative graphs.\n",
    "\n",
    "pandas: A powerful data manipulation and analysis library, particularly useful for working with structured data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = ['SepalLength', 'SepalWidth','PetalLength','PetalWidth', 'Species']\n",
    "df =pd.read_csv(r'C:/NORMAL_USE/py/my_venv/iris_spec/data.csv')\n",
    "print(df.head())\n",
    "print(df.head(150))\n",
    "#df.head(150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the CSV file into a pandas DataFrame\n",
    "pd.read_csv(): Reads a CSV file from the given file path and stores it in the variable 'df'\n",
    "The 'r' before the file path indicates a raw string, which ensures backslashes are handled correctly\n",
    "\n",
    "\n",
    "Displaying the first 5 rows of the DataFrame using the .head() method\n",
    "This is useful for quickly checking the structure and content of the dataset\n",
    "\n",
    "\n",
    "Displaying the first 150 rows of the DataFrame\n",
    "Useful when you want to inspect a larger portion of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the .describe() method to generate descriptive statistics for the DataFrame\n",
    "This includes summary statistics like count, mean, standard deviation, min, max, and percentiles (25%, 50%, 75%) for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,hue='Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize pairwise relationships with color differentiation by species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values  # Convert the DataFrame to a NumPy array\n",
    "x = data[:,0:4] # Extract the first four columns (features) as input data\n",
    "y = data[:, 4] # Extract the fifth column (target/label) as output data     \n",
    "print(x) # Print the input data (features)\n",
    "print(y) # Print the output data (labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # Import the function to split data into training and testing sets\n",
    "x_train , x_test , y_train , y_test = train_test_split(x ,y , test_size = 0.2) # Split the data into 80% training and 20% testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train)  # Print the training data for the input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test) # Print the x_test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train) # Print the y_train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test) # Print the y_test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model_svc = SVC() # Initialize the Support Vector Classifier model\n",
    "model_svc.fit(x_train, y_train) # Fit the model with the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1 = model_svc.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test , prediction1))  # Print the accuracy of the predictions\n",
    "for i in range(len(prediction1)): # Loop through the predictions and print the actual vs predicted values\n",
    "    print(y_test[i], prediction1[i])\n",
    "    accuracy = accuracy_score(y_test, prediction1) * 100 # Calculate the accuracy percentage\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "for i in range(len(prediction1)): # Check for mismatches between actual and predicted values and print them\n",
    "    if y_test[i] != prediction1[i]:\n",
    "        print(f\"Mismatch at index {i+1}: Actual = {y_test[i]}, Predicted = {prediction1[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_LR = LogisticRegression() # Initialize the Logistic Regression model\n",
    "\n",
    "model_LR.fit(x_train , y_train)# Fit the model with the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction2 = model_LR.predict(x_test) # Make predictions using the Logistic Regression model on the test data\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test , prediction2))\n",
    "for i in range(len(prediction2)): # Loop through the predictions and print the actual vs predicted value\n",
    "    print(y_test[i], prediction2[i])\n",
    "    accuracy = accuracy_score(y_test, prediction2) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "for i in range(len(prediction2)):\n",
    "    if y_test[i] != prediction2[i]:\n",
    "        print(f\"Mismatch at index {i}: Actual = {y_test[i]}, Predicted = {prediction2[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_DTC = DecisionTreeClassifier() # Initialize the Decision Tree Classifier model\n",
    "model_DTC.fit(x_train,y_train) #fit model with training data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction3 = model_DTC.predict(x_test) # Make predictions using the Decision Tree Classifier model on the test data\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test , prediction3))\n",
    "for i in range(len(prediction3)): # Loop through the predictions and print the actual vs predicted values\n",
    "    print(y_test[i], prediction3[i])\n",
    "    accuracy = accuracy_score(y_test, prediction3) * 100 #cal %\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "for i in range(len(prediction3)):\n",
    "    if y_test[i] != prediction3[i]:\n",
    "        print(f\"Mismatch at index {i+1}: Actual = {y_test[i]}, Predicted = {prediction3[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report #used for printing classification report \n",
    "print(classification_report(y_test, prediction2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_species = np.array([[5.2,2.6,1.5,0.6],[6.7 ,5.1, 3.8, 1.5],[15.3 , 2.5 , 4.6 ,1.9]]) # Define a new array of species data to predict\n",
    "#x_species = np.array([[3.5,5.6,8.5,7.6],[49, 6.1, 2.8, 4.0],[2, 7.2, 3.2, 6.0]])\n",
    "prediction = model_svc.predict(x_species) #prediction done on using SVC model \n",
    "print(\"prediction of species :{}\".format(prediction)) #species prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler # Import the RandomOverSampler class from the imbalanced-learn library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomOverSampler is used to balance imbalanced datasets by increasing the number of samples in the minority class through random duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(random_state=42) # Apply RandomOverSampler to balance the dataset\n",
    "x_resampled , y_resampled = oversample.fit_resample(x , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_resampled # The resampled feature matrix with  balanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resampled # The resampled target vector with balanced classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_resampled_train , x_resampled_test , y_resampled_train , y_resampled_test = train_test_split(x_resampled , y_resampled , test_size=0.25 , random_state=42)\n",
    "# Split the resampled data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "smote = SMOTE(random_state=42) # Initialize the SMOTE object and apply it to the training data\n",
    "x_resampled_train, y_resampled_train = smote.fit_resample(x_train, y_train)\n",
    "# Print the shapes of the resampled training data\n",
    "print(x_resampled_train.shape)\n",
    "print(y_resampled_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "y_resampled_series = pd.Series(y_resampled) # Convert the resampled target vector to a pandas Series and print the count of each class\n",
    "print(y_resampled_series.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled_train , X_resampled_test , y_resampled_train , y_resampled_test = train_test_split(x_resampled , y_resampled , test_size=0.25 , random_state=42) \n",
    "# Split the resampled data into training and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "smote = SMOTE(random_state=42)# Initialize SMOTE, apply it to the training data, and print the shapes of the resampled training data\n",
    "x_resampled_train, y_resampled_train = smote.fit_resample(x_train, y_train)\n",
    "print(x_resampled_train.shape)\n",
    "print(y_resampled_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = DecisionTreeClassifier()# Train the Decision Tree model on the resampled training data and evaluate its accuracy on the resampled test data\n",
    "model3.fit(x_resampled_train , y_resampled_train)\n",
    "y_pred_model3 = model3.predict(x_resampled_test)\n",
    "accuracy = accuracy_score(y_resampled_test , y_pred_model3)\n",
    "print(\"Accuracy score of Decision tree classifier :\" ,accuracy*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = SVC() # Train the SVC model on the resampled training data and evaluate its accuracy on the resampled test data\n",
    "model1.fit(x_resampled_train , y_resampled_train)\n",
    "y_pred_model1 = model1.predict(x_resampled_test)\n",
    "accuracy = accuracy_score(y_resampled_test , y_pred_model1)\n",
    "print(\"Accuracy score of SVC :\" ,accuracy*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LogisticRegression() # Train the Logistic Regression model on the resampled training data and evaluate its accuracy on the resampled test data\n",
    "model2.fit(x_resampled_train , y_resampled_train)\n",
    "y_pred_model2 = model2.predict(x_resampled_test)\n",
    "accuracy = accuracy_score(y_resampled_test , y_pred_model2)\n",
    "print(\"Accuracy score of Decision tree classifier :\" ,accuracy*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  classification_report\n",
    "def generate_classification_report(model_name , y_test , y_pred): # Define a function to generate and print the classification report for a given model\n",
    "\n",
    "    report = classification_report(y_test , y_pred)\n",
    "    print(f\"classifier report for {model_name}:\\n{report}\\n\")\n",
    "    \n",
    "# Generate and print classification reports for each model    \n",
    "generate_classification_report(model1 , y_resampled_test , y_pred_model1)\n",
    "generate_classification_report(model2 , y_resampled_test , y_pred_model2)\n",
    "generate_classification_report(model3, y_resampled_test , y_pred_model3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report \n",
    "import joblib as jb\n",
    "model3 = DecisionTreeClassifier() # Initialize, train, and evaluate the Decision Tree Classifier model\n",
    "model3.fit(x_resampled_train , y_resampled_train)\n",
    "y_pred_model3 = model3.predict(x_resampled_test)\n",
    "\n",
    "accuracy = accuracy_score(y_resampled_test , y_pred_model3) # Calculate and print the accuracy \n",
    "print(\"Accuracy score of decision tree classifier:\", accuracy * 100)\n",
    "\n",
    "classification_report = classification_report(y_resampled_test , y_pred_model3) # Generate and print the classification report\n",
    "print(\"classification_report:\\n\", classification_report)\n",
    "\n",
    "jb.dump(model3, ' DTC_model.pkl')\n",
    "# Save the trained model to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report \n",
    "import joblib as jb\n",
    "\n",
    "\n",
    "model2 = LogisticRegression()# Initialize, train, and evaluate \n",
    "model2.fit(x_resampled_train , y_resampled_train)\n",
    "y_pred_model2 = model2.predict(x_resampled_test)\n",
    "\n",
    "accuracy = accuracy_score(y_resampled_test , y_pred_model2)# Calculate and print the accuracy \n",
    "print(\"Accuracy score of logistic regression:\", accuracy * 100)\n",
    "\n",
    "classification_report = classification_report(y_resampled_test , y_pred_model2)\n",
    "print(\"classification_report:\\n\", classification_report)\n",
    "\n",
    "jb.dump(model2, ' LR_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report \n",
    "import joblib as jb\n",
    "\n",
    "model1.fit(x_resampled_train , y_resampled_train) # Train the SVC model on the resampled training data\n",
    "y_pred_model1 = model1.predict(x_resampled_test) # Make predictions on the resampled test data\n",
    "# Calculate and print the accuracy of the SVC model\n",
    "accuracy = accuracy_score(y_resampled_test , y_pred_model1)\n",
    "print(\"Accuracy score of SVC :\", accuracy * 100)\n",
    "classification_report = classification_report(y_resampled_test , y_pred_model1)# Generate and print the classification report for the SVC model\n",
    "print(\"classification_report:\\n\", classification_report)\n",
    "\n",
    "jb.dump(model1, ' SVC_model.pkl')# Save the trained SVC model to a file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_species = np.array([[15.3 , 2.5 , 4.6 ,1.9],[4.18,5.07,5.67,4.82],[1.56 , 1.84 , 1.60 ,0.36]])\n",
    "#x_species = np.array([[3.5,5.6,8.5,7.6],[49, 6.1, 2.8, 4.0],[2, 7.2, 3.2, 6.0]])\n",
    "# Predict the species using the trained Decision Tree Classifier model\n",
    "prediction = model_DTC.predict(x_species)\n",
    "print(\"prediction of species :{}\".format(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,hue='Species')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
